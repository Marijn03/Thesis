Machine learning models like deep neural networks are trained on specific data distributions. However, in the real world, test data can be different from the training data. This is known as out-of-distribution (OOD) data. Current models struggle to detect OOD samples reliably. The authors propose a new "generative classifier" model that learns the distributions of each class as separate Gaussian distributions in the latent space. By measuring the distance of a test sample from these class distributions, the model can better identify OOD samples while still accurately classifying in-distribution data. Experiments show this generative classifier outperforms existing methods for detecting OOD samples on image and tabular datasets, providing a promising approach for deploying robust machine learning models.
