The world of artificial intelligence and gaming is an ever-evolving field, and this paper delves into the challenges of creating robust agents within gaming environments. Reinforcement Learning (RL) agents often struggle to generalize their skills and adapt to new scenarios, a problem addressed in this research. By introducing a method called Invariance Regularization, the authors aim to enhance the agent's ability to navigate visually. The technique combines RL with supervised learning to encourage the agent to take appropriate actions despite variations in the environment. Experiments are designed using the VizDoom platform, offering customizable and diverse environments for testing. The results show that RL agents can overfit to specific environments, but with the proposed regularization method, they demonstrate improved generalization to unseen scenarios. This study highlights the importance of robust and adaptable agents, showcasing how RL can benefit from supervised learning techniques to enhance its performance and broaden its real-world applications. This research contributes to the growing field of AI, offering insights into creating more versatile and intelligent agents.
