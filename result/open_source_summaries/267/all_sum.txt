The document discusses how Convolutional Neural Networks (CNNs) are typically trained on specific image sizes, but they can still work well on different image sizes at test time. However, this can be a problem because it means that the network is not scale-invariant, meaning it's not robust to changes in image size. To address this issue, researchers have tried different methods, such as artificially increasing the dataset using transformations or modifying the network structure. However, these methods have limitations. In this work, the researchers propose a new method called "MixSize" that trains the network on multiple image sizes at the same time. This allows the network to be more resilient to changes in image size and generalize well to small images. As a result, the network can be evaluated at smaller image sizes, which reduces the computational cost and allows for faster inference. For example, the researchers were able to achieve the same level of accuracy as the baseline model with 2x fewer computations. Additionally, the MixSize method can also be used to accelerate training or improve the final accuracy of the model. The researchers demonstrate the effectiveness of the MixSize method on various image sizes and tasks, showing that it can improve model performance and reduce computational cost.
