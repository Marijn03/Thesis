Unsupervised embedding learning is a technique used in computer vision that helps machines learn from images without using labeled data. The goal is to extract meaningful features from the images, which can be used for various tasks such as image clustering and recognition. In this paper, the authors propose a new model called Super-AND, which combines the advantages of existing techniques to achieve better results. Super-AND uses a combination of losses to make similar images gather together in the feature space and keep the features invariant against image augmentation. The authors tested Super-AND on various benchmark datasets and achieved an accuracy of 89.2% in the CIFAR-10 dataset, outperforming existing models. This is a significant breakthrough in the field of unsupervised embedding learning, as it makes it possible to train models without labeled data, which can be expensive and time-consuming to obtain.
